{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"fancyzhx/dbpedia_14\")\n",
    "CLASS_LABELS = ds['train'].features['label'].names\n",
    "CLASS_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain first n samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_samples_per_class(dataset, n, shuffle = False):\n",
    "    \"\"\"\n",
    "        Given a test dataset, select n samples from each class\n",
    "        and return a smaller dataset containing all the samples.\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): The test dataset to sample.\n",
    "            n (int): How many samples from each class to extract.\n",
    "            shuffle (bool): Whether to sort the final result by class or randomly. NOTE: Dataset.shuffle() hangs indefinitely on Nix.\n",
    "        \n",
    "        Returns:\n",
    "            sample (Dataset): The sampled dataset.\n",
    "    \"\"\"\n",
    "    ds_sorted = dataset.sort('label')\n",
    "    _, class_indices = np.unique(ds_sorted['label'], return_index=True)\n",
    "\n",
    "    \n",
    "    class_indices = np.array([list(range(index, index + n)) for index in class_indices])\n",
    "    class_indices = class_indices.flatten()\n",
    "\n",
    "    if shuffle:\n",
    "        sample = dataset.shuffle().sort('label').select(class_indices) # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
    "    else:\n",
    "        sample = dataset.sort('label').select(class_indices)\n",
    "    \n",
    "    if shuffle: sample = sample.shuffle() # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = get_n_samples_per_class(ds['test'], 3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt to classify articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You are an expert in classifying articles into categories.\n",
    "Your task is to read an article, decide which category it belongs into, and then return the number of that category.\n",
    "There are 14 categories you may choose from, but you can only decide one category.\n",
    "\n",
    "CATEGORIES:\n",
    "1. Company\n",
    "2. Educational Institution\n",
    "3. Artist\n",
    "4. Athlete\n",
    "5. Office Holder\n",
    "6. Method Of Transportation\n",
    "7. Building\n",
    "8. Natural Place\n",
    "9. Village\n",
    "10. Animal\n",
    "11. Plant\n",
    "12. Album\n",
    "13. Film\n",
    "14. Written Work\n",
    "\n",
    "Read the following article and return only the number of its category.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_prompt(article):\n",
    "    \"\"\"\n",
    "        For a given article in the Dataset,\n",
    "        return a LLM prompt in chat template form\n",
    "        to get its category.\n",
    "\n",
    "        Args:\n",
    "            article (Dictionary): Any item in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            prompt (Dictionary): The prompt as a [Chat Template](https://huggingface.co/docs/transformers/main/en/chat_templating).\n",
    "    \"\"\"\n",
    "    return [\n",
    "      {\"role\": \"system\", \"content\": PROMPT},\n",
    "      {\"role\": \"user\", \"content\": article[\"content\"].strip()},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    GenerationConfig\n",
    ")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='microsoft/phi-2'\n",
    "device_map = {\"\": 0}\n",
    "original_model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                                      device_map=device_map,\n",
    "                                                      quantization_config=bnb_config,\n",
    "                                                      trust_remote_code=True,\n",
    "                                                      use_auth_token=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
