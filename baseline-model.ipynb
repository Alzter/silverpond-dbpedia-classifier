{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKRSEolKGDiw"
      },
      "source": [
        "# Load DBPedia dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCnfFuWPWr9-"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"fancyzhx/dbpedia_14\")\n",
        "CLASS_LABELS = ds['train'].features['label'].names\n",
        "CLASS_LABELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY442nBwWr-A"
      },
      "source": [
        "# Obtain first n samples from each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dvYnTRrWr-C"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4j8rSsCWr-D"
      },
      "outputs": [],
      "source": [
        "def get_n_samples_per_class(dataset, n, shuffle = False):\n",
        "    \"\"\"\n",
        "        Given a test dataset, select n samples from each class\n",
        "        and return a smaller dataset containing all the samples.\n",
        "\n",
        "        Args:\n",
        "            dataset (Dataset): The test dataset to sample.\n",
        "            n (int): How many samples from each class to extract.\n",
        "            shuffle (bool): Whether to sort the final result by class or randomly. NOTE: Dataset.shuffle() hangs indefinitely on Nix.\n",
        "\n",
        "        Returns:\n",
        "            sample (Dataset): The sampled dataset.\n",
        "    \"\"\"\n",
        "    ds_sorted = dataset.sort('label')\n",
        "    _, class_indices = np.unique(ds_sorted['label'], return_index=True)\n",
        "\n",
        "\n",
        "    class_indices = np.array([list(range(index, index + n)) for index in class_indices])\n",
        "    class_indices = class_indices.flatten()\n",
        "\n",
        "    if shuffle:\n",
        "        sample = dataset.shuffle().sort('label').select(class_indices) # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
        "    else:\n",
        "        sample = dataset.sort('label').select(class_indices)\n",
        "\n",
        "    if shuffle: sample = sample.shuffle() # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPbBqs74Wr-E"
      },
      "outputs": [],
      "source": [
        "small_dataset = get_n_samples_per_class(ds['test'], 3, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46yLfxYMWr-H"
      },
      "source": [
        "# Prompt to classify articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qQAMgasWr-H"
      },
      "outputs": [],
      "source": [
        "# Zero-shot prompt to classify articles and return their category ID.\n",
        "PROMPT_ZEROSHOT = \"\"\"You are an expert in classifying articles into categories.\n",
        "Your task is to read an article, decide which category it belongs into, and then return the number of that category.\n",
        "There are 14 categories you may choose from, but you can only decide one category.\n",
        "\n",
        "CATEGORIES:\n",
        "0. Company\n",
        "1. Educational Institution\n",
        "2. Artist\n",
        "3. Athlete\n",
        "4. Office Holder\n",
        "5. Method Of Transportation\n",
        "6. Building\n",
        "7. Natural Place\n",
        "8. Village\n",
        "9. Animal\n",
        "10. Plant\n",
        "11. Album\n",
        "12. Film\n",
        "13. Written Work\n",
        "\n",
        "Read the following article and return the most suitable category as a number (\"0\"), NOT as text (\"Company\").\n",
        "\"\"\"\n",
        "\n",
        "# Zero-shot chain-of-thought prompt to classify articles and return their category name.\n",
        "PROMPT_COT = \"\"\"You are an expert at classifying articles into the following categories:\n",
        "\n",
        "CATEGORIES:\n",
        "0. Company\n",
        "1. Educational Institution\n",
        "2. Artist\n",
        "3. Athlete\n",
        "4. Office Holder\n",
        "5. Method Of Transportation\n",
        "6. Building\n",
        "7. Natural Place\n",
        "8. Village\n",
        "9. Animal\n",
        "10. Plant\n",
        "11. Album\n",
        "12. Film\n",
        "13. Written Work\n",
        "\n",
        "Read the following article and explain which category describes its content best.\n",
        "End your answer with the category name.\n",
        "Let's think step by step.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gq0uPzxWr-I"
      },
      "outputs": [],
      "source": [
        "def get_classification_prompt(article, prompt):\n",
        "    \"\"\"\n",
        "      For a given article in the Dataset,\n",
        "      return a LLM prompt in chat template form\n",
        "      to get its category.\n",
        "\n",
        "      Args:\n",
        "          article (Dictionary): Any item in the dataset.\n",
        "          prompt (str): A model prompt with article classification instructions.\n",
        "\n",
        "      Returns:\n",
        "          prompt (Dictionary): The prompt as a [Chat Template](https://huggingface.co/docs/transformers/main/en/chat_templating).\n",
        "    \"\"\"\n",
        "    return [\n",
        "      {\"role\": \"system\", \"content\": prompt},\n",
        "      {\"role\": \"user\", \"content\": article[\"content\"].strip()},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coDi5e9WWr-K"
      },
      "source": [
        "# Load LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmWm8kV9Wr-K"
      },
      "source": [
        "To access the LLM (C4AI Command R7B), you will need to accept a license agreement on Hugging Face.\n",
        "\n",
        "STEPS:\n",
        "1. Log into hugging face\n",
        "2. Accept the license agreement [here](https://huggingface.co/CohereForAI/c4ai-command-r7b-12-2024)\n",
        "3. Replace variable ``YOUR_HF_TOKEN`` with your Hugging Face token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kihhy5KlWr-L"
      },
      "outputs": [],
      "source": [
        "HF_TOKEN = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCtNgkdbeVHT"
      },
      "outputs": [],
      "source": [
        "from accelerate.test_utils.testing import get_backend\n",
        "\n",
        "DEVICE, _, _ = get_backend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpf3SAVJWr-L"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"CohereForAI/c4ai-command-r7b-12-2024\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN, device_map=\"auto\")\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, token=HF_TOKEN, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W56z0RHRf3mL"
      },
      "outputs": [],
      "source": [
        "import transformers, torch\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    token=HF_TOKEN,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Un3PF5fr-1"
      },
      "source": [
        "# Model testing method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_NAMES=[\n",
        "    \"Company\",\n",
        "    \"Educational Institution\",\n",
        "    \"Artist\",\n",
        "    \"Athlete\",\n",
        "    \"Office Holder\",\n",
        "    \"Method Of Transportation\",\n",
        "    \"Building\",\n",
        "    \"Natural Place\",\n",
        "    \"Village\",\n",
        "    \"Animal\",\n",
        "    \"Plant\",\n",
        "    \"Album\",\n",
        "    \"Film\",\n",
        "    \"Written Work\"\n",
        "]\n",
        "\n",
        "def get_class_label_from_string(string, class_labels = LABEL_NAMES):\n",
        "  \"\"\"\n",
        "  Extract a class label by name from a string and return its ID.\n",
        "  If no match is found, raise an Exception.\n",
        "\n",
        "  Args:\n",
        "    string (str): A string containing the name of one class label.\n",
        "\n",
        "  Returns:\n",
        "    class_id (int): The ID of the matching class label.\n",
        "  \"\"\"\n",
        "  string = string.lower().strip()\n",
        "\n",
        "  for (id, label) in class_labels: # For each class label:\n",
        "    # If we can find a direct match of the class label anywhere in the string:\n",
        "    if (string.find(label.lower()) != -1):\n",
        "      return id # Return the ID of the matching class label.\n",
        "\n",
        "  raise Exception(f\"No class label found in string: {string}\")"
      ],
      "metadata": {
        "id": "q_8az0xNY88d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3Dt-uW3dmLj"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_first_number_from_string(string):\n",
        "  \"\"\"\n",
        "  Returns the first whole number from a string as an integer.\n",
        "  \"\"\"\n",
        "  first_number=re.findall(r\"\\d+\",string)\n",
        "  if first_number is not None:\n",
        "    first_number = int(first_number[0])\n",
        "    return first_number\n",
        "  else:\n",
        "    raise Exception(f\"No number found in string: {string}\")\n",
        "\n",
        "def get_category_label(article, classification_prompt, extractor_func, max_tokens = 10):\n",
        "  \"\"\"\n",
        "  For a given article in the DBPedia dataset, predict its category label.\n",
        "\n",
        "  Args:\n",
        "    article (str): Article contents as raw text.\n",
        "    classifiction_prompt (str): Model instructions on how to classify articles.\n",
        "    extractor_func (func): A method which takes the model's response and returns a classification label as an integer.\n",
        "    max_tokens (int): Model response word limit.\n",
        "\n",
        "  Returns:\n",
        "    class_id (int): The category of the article.\n",
        "  \"\"\"\n",
        "  input = get_classification_prompt(article, classification_prompt)\n",
        "\n",
        "  chat_history = pipeline(\n",
        "      input,\n",
        "      do_sample=True,\n",
        "      #top_k=10,\n",
        "      #num_return_sequences=1,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        "      max_new_tokens=max_tokens,\n",
        "      temperature=0.001\n",
        "      #continue_final_message=continue_final_message\n",
        "  )\n",
        "\n",
        "  response = chat_history[0][\"generated_text\"][-1]['content']\n",
        "\n",
        "  class_id = extractor_func(response)\n",
        "\n",
        "  return class_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xhhly4zjscN"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def predict_classes(dataset, classification_prompt, extractor_func, max_tokens):\n",
        "  \"\"\"\n",
        "    For a given RFPedia dataset, use the contents of each article to predict its label.\n",
        "\n",
        "    Args:\n",
        "      dataset (Dataset): The dataset to sample.\n",
        "      classifiction_prompt (str): Model instructions on how to classify articles.\n",
        "      extractor_func (func): A method which takes the model's response and returns a classification label as an integer.\n",
        "      max_tokens (int): Model response word limit.\n",
        "\n",
        "    Returns:\n",
        "      results (tuple<list, list>): Two lists: ``y_pred`` (predicted labels) and ``y_true`` (actual labels).\n",
        "  \"\"\"\n",
        "  y_pred = []\n",
        "  y = []\n",
        "\n",
        "  for item in tqdm(dataset):\n",
        "    y_pred.append( get_category_label(item, classification_prompt, extractor_func, max_tokens) )\n",
        "    y.append( item['label' ])\n",
        "\n",
        "  return y_pred, y_true"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "OJmzrHaLg3YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configurations = [\n",
        "    {\"name\" : \"Zero-shot\",\n",
        "     \"prompt\" : PROMPT_ZEROSHOT,\n",
        "     \"max_tokens\" : 10,\n",
        "     \"extractor_func\" : get_first_number_from_string},\n",
        "\n",
        "    {\"name\" : \"Chain-of-Thought\",\n",
        "     \"prompt\" : PROMPT_COT,\n",
        "     \"max_tokens\" : 50,\n",
        "     \"extractor_func\" : get_class_label_from_string}\n",
        "]"
      ],
      "metadata": {
        "id": "BhwWWSqog7a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict all article categories in the dataset\n",
        "\n",
        "y_true = None\n",
        "test_data = small_dataset['test']\n",
        "\n",
        "for config in configurations:\n",
        "\n",
        "  args = config['prompt'], config['extractor_func'], config['max_tokens']\n",
        "\n",
        "  config['y_pred'], config['y_true'] = predict_classes(test_data, *args)"
      ],
      "metadata": {
        "id": "0gx668V-G5ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model"
      ],
      "metadata": {
        "id": "o4Ib_XV9GKIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def evaluate_model(config):\n",
        "  y_true, y_pred, config_name = config['y_true'], config['y_pred'], config['name']\n",
        "  print(f\"{config_name} evaluation results\")\n",
        "\n",
        "  # Get precision, recall, and F1 score\n",
        "  classif_report = classification_report(y_true, y_pred)\n",
        "\n",
        "  print(classif_report)\n",
        "\n",
        "  # Get confusion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred, labels=CLASS_LABELS)\n",
        "  disp = ConfusionMatrixDisplay(\n",
        "      confusion_matrix=cm,\n",
        "      display_labels = CLASS_LABELS,\n",
        "      cmap = plt.cm.Blues,\n",
        "      normalize=True)\n",
        "  disp.ax_.set_title(config_name)\n",
        "\n",
        "  disp.plot()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "hmkxjb4_GLBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for config in configurations:\n",
        "  evaluate_model(config)"
      ],
      "metadata": {
        "id": "cG8XcJOpjjui"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}