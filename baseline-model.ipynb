{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKRSEolKGDiw"
      },
      "source": [
        "# Load DBPedia dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxJLdEFvmkNt"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCnfFuWPWr9-"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"fancyzhx/dbpedia_14\")\n",
        "CLASS_LABELS = ds['train'].features['label'].names\n",
        "CLASS_LABELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY442nBwWr-A"
      },
      "source": [
        "# Obtain first n samples from each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dvYnTRrWr-C"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4j8rSsCWr-D"
      },
      "outputs": [],
      "source": [
        "def get_n_samples_per_class(dataset, n, shuffle = False):\n",
        "    \"\"\"\n",
        "        Given a test dataset, select n samples from each class\n",
        "        and return a smaller dataset containing all the samples.\n",
        "\n",
        "        Args:\n",
        "            dataset (Dataset): The test dataset to sample.\n",
        "            n (int): How many samples from each class to extract.\n",
        "            shuffle (bool): Whether to sort the final result by class or randomly. NOTE: Dataset.shuffle() hangs indefinitely on Nix.\n",
        "\n",
        "        Returns:\n",
        "            sample (Dataset): The sampled dataset.\n",
        "    \"\"\"\n",
        "    ds_sorted = dataset.sort('label')\n",
        "    _, class_indices = np.unique(ds_sorted['label'], return_index=True)\n",
        "\n",
        "\n",
        "    class_indices = np.array([list(range(index, index + n)) for index in class_indices])\n",
        "    class_indices = class_indices.flatten()\n",
        "\n",
        "    if shuffle:\n",
        "        sample = dataset.shuffle().sort('label').select(class_indices) # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
        "    else:\n",
        "        sample = dataset.sort('label').select(class_indices)\n",
        "\n",
        "    if shuffle: sample = sample.shuffle() # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPbBqs74Wr-E"
      },
      "outputs": [],
      "source": [
        "small_dataset = get_n_samples_per_class(ds['test'], 6, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46yLfxYMWr-H"
      },
      "source": [
        "# Prompt to classify articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qQAMgasWr-H"
      },
      "outputs": [],
      "source": [
        "# Zero-shot prompt to classify articles and return their category ID.\n",
        "PROMPT_ZEROSHOT = \"\"\"You are an expert in classifying articles into categories.\n",
        "Your task is to read an article, decide which category it belongs into, and then return the number of that category.\n",
        "There are 14 categories you may choose from, but you can only decide one category.\n",
        "\n",
        "CATEGORIES:\n",
        "0. Company\n",
        "1. Educational Institution\n",
        "2. Artist\n",
        "3. Athlete\n",
        "4. Office Holder\n",
        "5. Method Of Transportation\n",
        "6. Building\n",
        "7. Natural Place\n",
        "8. Village\n",
        "9. Animal\n",
        "10. Plant\n",
        "11. Album\n",
        "12. Film\n",
        "13. Written Work\n",
        "\n",
        "Read the following article and return the most suitable category as a number (\"0\"), NOT as text (\"Company\").\n",
        "\"\"\"\n",
        "\n",
        "# Zero-shot chain-of-thought prompt to classify articles and return their category name.\n",
        "PROMPT_COT = \"\"\"You are an expert at classifying articles into the following categories:\n",
        "\n",
        "CATEGORIES:\n",
        "0. Company\n",
        "1. Educational Institution\n",
        "2. Artist\n",
        "3. Athlete\n",
        "4. Office Holder\n",
        "5. Method Of Transportation\n",
        "6. Building\n",
        "7. Natural Place\n",
        "8. Village\n",
        "9. Animal\n",
        "10. Plant\n",
        "11. Album\n",
        "12. Film\n",
        "13. Written Work\n",
        "\n",
        "Read the following article and explain which category describes its content best.\n",
        "End your answer with the category name.\n",
        "Let's think step by step.\n",
        "\"\"\"\n",
        "\n",
        "# Meta prompt - A type of zero-shot prompt which prioritises abstract reasoning over concrete examples.\n",
        "# Advantages: Fewer tokens. Disadvantages:\n",
        "# https://www.promptingguide.ai/techniques/meta-prompting\n",
        "PROMPT_META = \"\"\"Problem: [excerpt from an encyclopedia article]\n",
        "\n",
        "Solution Structure:\n",
        "1. Begin the response with \"Let's think step by step\".\n",
        "2. Identify the subject of the encyclopedia article with \"This encyclopedia article is about [subject]\".\n",
        "3. Define what the subject is. Is it natural or artificial? Is it one or multiple entities? Use \"[subject] is a [classification]\".\n",
        "4. Consider the following list of categories:\n",
        "\t- Company\n",
        "\t- Educational Institution\n",
        "\t- Artist\n",
        "\t- Athlete\n",
        "\t- Office Holder\n",
        "\t- Method Of Transportation\n",
        "\t- Building\n",
        "\t- Natural Place\n",
        "\t- Village\n",
        "\t- Animal\n",
        "\t- Plant\n",
        "\t- Album\n",
        "\t- Film\n",
        "\t- Written Work\n",
        "   Identify all categories in this list whose properties do not match the subject.\n",
        "5. Identify which category has the most in common with the subject and explain why.\n",
        "6. Finally, state \"Category: [best matching category].\"\n",
        "\"\"\"\n",
        "\n",
        "# Few-shot chain-of-thought prompt to classify articles and return their category name.\n",
        "PROMPT_COT_4SHOT = \"\"\"Read an encyclopedia article excerpt and give it one of the following categories:\n",
        "\n",
        "CATEGORIES:\n",
        "- Company\n",
        "- Educational Institution\n",
        "- Artist\n",
        "- Athlete\n",
        "- Office Holder\n",
        "- Method Of Transportation\n",
        "- Building\n",
        "- Natural Place\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- Written Work\n",
        "\n",
        "Problem:\n",
        "The Petlyakov VI-100 (Visotnyi Istrebitel – high altitude fighter) was a fighter/dive bomber aircraft designed and built in the USSR from 1938.\n",
        "\n",
        "Solution:\n",
        "Let's think step by step. This encyclopedia article is about the Petlyakov VI-100, which is an aircraft. While aircrafts are a man-made structure designed and built for a specific purpose, they are not human habitats with walls and a ceiling, so Building is not the category. Aircrafts are designed to transport people, so Method Of Transportation is the best category. Category: Method Of Transportation.\n",
        "\n",
        "Problem:\n",
        "Kruszewo [kruˈʂɛvɔ] is a village in the administrative district of Gmina Żuromin within Żuromin County Masovian Voivodeship in east-central Poland.\n",
        "\n",
        "Solution:\n",
        "Let's think step by step. This encyclopedia article is about Kruszewo, which is a village in Poland. While villages do exist within geographical areas, they are man-made, so Natural Place is not the category. While villages do contain buildings, they are not a single building, so Building is not the category. The most matching category is therefore Village. Category: Village.\n",
        "\n",
        "Problem:\n",
        "Schismus is a genus of grass in the Poaceae family. They are native to Africa and Asia.\n",
        "\n",
        "Solution:\n",
        "Let's think step by step. This encyclopedia article is about Schismus, which is a biological species. The genus of the species is grass. Grass is commonly found in natural places, but Schismus is not a geographical location, so Natural Place is not the category. Grass is a type of plant, so Plant is the most fitting category. Category: Plant.\n",
        "\n",
        "Problem:\n",
        "The Southern Oklahoma Cosmic Trigger Contest is a soundtrack by The Flaming Lips to the Bradley Beesley fishing documentary Okie Noodling.\n",
        "\n",
        "Solution:\n",
        "Let's think step by step. This encyclopedia article is about The Southern Oklahoma Cosmic Trigger Contest, which is a soundtrack to a fishing documentary. While the article mentions a fishing documentary, it is not the subject, so Film is not the category. While the article mentions the band The Flaming Lips, they are not the subject, so Artist is not the category. The most suitable category is therefore Album. Category: Album.\n",
        "\n",
        "Problem:\n",
        "\"\"\"\n",
        "\n",
        "# Few-shot chain-of-thought prompt to classify articles and return their category name.\n",
        "PROMPT_COT_2SHOT = \"\"\"Read an encyclopedia article excerpt and give it one of the following categories:\n",
        "\n",
        "CATEGORIES:\n",
        "- Company\n",
        "- Educational Institution\n",
        "- Artist\n",
        "- Athlete\n",
        "- Office Holder\n",
        "- Method Of Transportation\n",
        "- Building\n",
        "- Natural Place\n",
        "- Village\n",
        "- Animal\n",
        "- Plant\n",
        "- Album\n",
        "- Film\n",
        "- Written Work\n",
        "\n",
        "Problem:\n",
        "The Petlyakov VI-100 (Visotnyi Istrebitel – high altitude fighter) was a fighter/dive bomber aircraft designed and built in the USSR from 1938.\n",
        "\n",
        "Solution:\n",
        "Let's think step by step. This encyclopedia article is about the Petlyakov VI-100, which is an aircraft. While aircrafts are a man-made structure designed and built for a specific purpose, they are not human habitats with walls and a ceiling, so Building is not the category. Aircrafts are designed to transport people, so Method Of Transportation is the best category. Category: Method Of Transportation.\n",
        "\n",
        "Problem:\n",
        "Schismus is a genus of grass in the Poaceae family. They are native to Africa and Asia.\n",
        "\n",
        "Solution:\n",
        "Let's think step by step. This encyclopedia article is about Schismus, which is a biological species. The genus of the species is grass. Grass is commonly found in natural places, but Schismus is not a geographical location, so Natural Place is not the category. Grass is a type of plant, so Plant is the most fitting category. Category: Plant.\n",
        "\n",
        "Problem:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gq0uPzxWr-I"
      },
      "outputs": [],
      "source": [
        "def get_classification_prompt(article, prompt):\n",
        "    \"\"\"\n",
        "      For a given article in the Dataset,\n",
        "      return a LLM prompt in chat template form\n",
        "      to get its category.\n",
        "\n",
        "      Args:\n",
        "          article (Dictionary): Any item in the dataset.\n",
        "          prompt (str): A model prompt with article classification instructions.\n",
        "\n",
        "      Returns:\n",
        "          prompt (Dictionary): The prompt as a [Chat Template](https://huggingface.co/docs/transformers/main/en/chat_templating).\n",
        "    \"\"\"\n",
        "    return [\n",
        "      {\"role\": \"system\", \"content\": prompt},\n",
        "      {\"role\": \"user\", \"content\": article[\"content\"].strip()},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coDi5e9WWr-K"
      },
      "source": [
        "# Load LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmWm8kV9Wr-K"
      },
      "source": [
        "To access the LLM (C4AI Command R7B), you will need to accept a license agreement on Hugging Face.\n",
        "\n",
        "STEPS:\n",
        "1. Log into hugging face\n",
        "2. Accept the license agreement [here](https://huggingface.co/CohereForAI/c4ai-command-r7b-12-2024)\n",
        "3. Replace variable ``YOUR_HF_TOKEN`` with your Hugging Face token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kihhy5KlWr-L"
      },
      "outputs": [],
      "source": [
        "HF_TOKEN = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCtNgkdbeVHT"
      },
      "outputs": [],
      "source": [
        "from accelerate.test_utils.testing import get_backend\n",
        "\n",
        "DEVICE, _, _ = get_backend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpf3SAVJWr-L"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"CohereForAI/c4ai-command-r7b-12-2024\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN, device_map=\"auto\")\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, token=HF_TOKEN, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W56z0RHRf3mL"
      },
      "outputs": [],
      "source": [
        "import transformers, torch\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    token=HF_TOKEN,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Un3PF5fr-1"
      },
      "source": [
        "# Model testing method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNLzAeHbR3X9"
      },
      "outputs": [],
      "source": [
        "LABEL_NAMES=[\n",
        "    \"Company\",\n",
        "    \"Educational Institution\",\n",
        "    \"Artist\",\n",
        "    \"Athlete\",\n",
        "    \"Office Holder\",\n",
        "    \"Method Of Transportation\",\n",
        "    \"Building\",\n",
        "    \"Natural Place\",\n",
        "    \"Village\",\n",
        "    \"Animal\",\n",
        "    \"Plant\",\n",
        "    \"Album\",\n",
        "    \"Film\",\n",
        "    \"Written Work\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_8az0xNY88d"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "LABEL_NAMES=[\n",
        "    \"Company\",\n",
        "    \"Educational Institution\",\n",
        "    \"Artist\",\n",
        "    \"Athlete\",\n",
        "    \"Office Holder\",\n",
        "    \"Method Of Transportation\",\n",
        "    \"Building\",\n",
        "    \"Natural Place\",\n",
        "    \"Village\",\n",
        "    \"Animal\",\n",
        "    \"Plant\",\n",
        "    \"Album\",\n",
        "    \"Film\",\n",
        "    \"Written Work\"\n",
        "]\n",
        "\n",
        "def get_class_label_from_string(string, class_labels = LABEL_NAMES):\n",
        "    \"\"\"\n",
        "    Extract a class label by name from a string and return its ID.\n",
        "    If no match is found, choose a random label ID.\n",
        "\n",
        "    Args:\n",
        "    string (str): A string containing the name of one class label.\n",
        "\n",
        "    Returns:\n",
        "    class_id (int): The ID of the matching class label.\n",
        "    \"\"\"\n",
        "    string = string.lower().strip()\n",
        "\n",
        "    # Concatenate all label names using boolean OR.\n",
        "    match = \"|\".join(LABEL_NAMES).lower().replace(\" \", r\"\\s*\")\n",
        "\n",
        "    # Find all instances of label name strings within the base string.\n",
        "    matches = re.findall(match, string)\n",
        "\n",
        "    # If no class label is found in the LLM text, pick a random label.\n",
        "    if matches == []:\n",
        "        print(f\"No class label found in string: {string}\")\n",
        "        return random.randint(0, len(LABEL_NAMES) - 1)\n",
        "\n",
        "    # Get the last matching label from the string.\n",
        "    final_match = matches[-1]\n",
        "\n",
        "    # Remove all capitalisation, non-alphabetic characters, and whitespace\n",
        "    labels_sanitised = [re.sub(\"[^a-z]\", \"\", label.lower()) for label in LABEL_NAMES]\n",
        "    match_sanitised = re.sub(\"[^a-z]\", \"\", final_match.lower())\n",
        "\n",
        "    # Find the matching class ID for the label.\n",
        "    class_id = labels_sanitised.index(match_sanitised)\n",
        "    return class_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3Dt-uW3dmLj"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_first_number_from_string(string):\n",
        "  \"\"\"\n",
        "  Returns the first whole number from a string as an integer.\n",
        "  \"\"\"\n",
        "  first_number=re.findall(r\"\\d+\",string)\n",
        "  if first_number is not None:\n",
        "    first_number = int(first_number[0])\n",
        "    return first_number\n",
        "  else:\n",
        "    raise Exception(f\"No number found in string: {string}\")\n",
        "\n",
        "def get_category_label(article, classification_prompt, extractor_func, max_tokens = 10):\n",
        "  \"\"\"\n",
        "  For a given article in the DBPedia dataset, predict its category label.\n",
        "\n",
        "  Args:\n",
        "    article (str): Article contents as raw text.\n",
        "    classifiction_prompt (str): Model instructions on how to classify articles.\n",
        "    extractor_func (func): A method which takes the model's response and returns a classification label as an integer.\n",
        "    max_tokens (int): Model response word limit.\n",
        "\n",
        "  Returns:\n",
        "    output (tuple<int, str>): The category of the article and the raw LLM output.\n",
        "  \"\"\"\n",
        "  input = get_classification_prompt(article, classification_prompt)\n",
        "\n",
        "  chat_history = pipeline(\n",
        "      input,\n",
        "      do_sample=True,\n",
        "      #top_k=10,\n",
        "      #num_return_sequences=1,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        "      max_new_tokens=max_tokens,\n",
        "      temperature=0.001\n",
        "      #continue_final_message=continue_final_message\n",
        "  )\n",
        "\n",
        "  response = chat_history[0][\"generated_text\"][-1]['content']\n",
        "\n",
        "  class_id = extractor_func(response)\n",
        "\n",
        "  return (class_id, response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xhhly4zjscN"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def predict_classes(dataset, classification_prompt, extractor_func, max_tokens):\n",
        "  \"\"\"\n",
        "    For a given RFPedia dataset, use the contents of each article to predict its label.\n",
        "\n",
        "    Args:\n",
        "      dataset (Dataset): The dataset to sample.\n",
        "      classifiction_prompt (str): Model instructions on how to classify articles.\n",
        "      extractor_func (func): A method which takes the model's response and returns a classification label as an integer.\n",
        "      max_tokens (int): Model response word limit.\n",
        "\n",
        "    Returns:\n",
        "      results (tuple<list, list, list>):\n",
        "        y_pred (list<int>): Predicted labels\n",
        "        y_true (list<int>): Actual labels (groundtruth)\n",
        "        responses (list<str>): Raw LLM response for each test sample.\n",
        "  \"\"\"\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "  responses = []\n",
        "\n",
        "  for item in tqdm(dataset, \"Classifying articles\"):\n",
        "\n",
        "    pred_label, response = get_category_label(item, classification_prompt, extractor_func, max_tokens)\n",
        "\n",
        "    y_pred.append( pred_label )\n",
        "    y_true.append( item['label' ])\n",
        "    responses.append( response )\n",
        "\n",
        "  return y_pred, y_true, responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJmzrHaLg3YL"
      },
      "source": [
        "# Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhwWWSqog7a7"
      },
      "outputs": [],
      "source": [
        "configurations = [\n",
        "    # {\"name\" : \"Zero-shot\",\n",
        "    #  \"prompt\" : PROMPT_ZEROSHOT,\n",
        "    #  \"max_tokens\" : 10,\n",
        "    #  \"extractor_func\" : get_first_number_from_string},\n",
        "\n",
        "    # {\"name\" : \"Chain-of-Thought\",\n",
        "    #  \"prompt\" : PROMPT_COT,\n",
        "    #  \"max_tokens\" : 100,\n",
        "    #  \"extractor_func\" : get_class_label_from_string},\n",
        "\n",
        "    {\"name\" : \"Meta Prompt\",\n",
        "     \"prompt\" : PROMPT_META,\n",
        "     \"max_tokens\" : 100,\n",
        "     \"extractor_func\" : get_class_label_from_string},\n",
        "\n",
        "    {\"name\" : \"2-Shot CoT\",\n",
        "     \"prompt\" : PROMPT_COT_2SHOT,\n",
        "     \"max_tokens\" : 100,\n",
        "     \"extractor_func\" : get_class_label_from_string},\n",
        "\n",
        "    {\"name\" : \"4-Shot CoT\",\n",
        "     \"prompt\" : PROMPT_COT_4SHOT,\n",
        "     \"max_tokens\" : 100,\n",
        "     \"extractor_func\" : get_class_label_from_string}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gx668V-G5ay"
      },
      "outputs": [],
      "source": [
        "# Predict all article categories in the dataset\n",
        "\n",
        "y_true = None\n",
        "test_data = small_dataset\n",
        "\n",
        "for config in tqdm(configurations, \"Testing LLM configurations\"):\n",
        "\n",
        "  args = config['prompt'], config['extractor_func'], config['max_tokens']\n",
        "\n",
        "  config['y_pred'], config['y_true'], config['responses'] = predict_classes(test_data, *args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Ib_XV9GKIr"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0095MWNzlFp"
      },
      "source": [
        "## Accuracy report + confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmkxjb4_GLBN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def evaluate_model(config):\n",
        "  \"\"\"\n",
        "  Evaluate a model configuration and save the results to output_dir.\n",
        "  \"\"\"\n",
        "\n",
        "  output_dir = os.path.join(\"output\", config['name'].replace(' ', '_').lower())\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "  y_true, y_pred, config_name = config['y_true'], config['y_pred'], config['name']\n",
        "  print(f\"\\n{config_name} evaluation results\\n\")\n",
        "\n",
        "  # Get precision, recall, and F1 score\n",
        "  classif_report = classification_report(y_true, y_pred, zero_division=0.0, output_dict=True)\n",
        "  classif_report = pd.DataFrame(classif_report).transpose()\n",
        "\n",
        "  print(classif_report)\n",
        "\n",
        "  # Save classification report to output dir\n",
        "  classif_report.to_csv( os.path.join(output_dir, \"evaluation.csv\"), escapechar='\\\\' )\n",
        "\n",
        "  # Display confusion matrix\n",
        "  try:\n",
        "    disp = ConfusionMatrixDisplay.from_predictions(\n",
        "        y_true, y_pred,\n",
        "        display_labels = CLASS_LABELS,\n",
        "        cmap = plt.cm.Blues,\n",
        "        xticks_rotation='vertical')\n",
        "  except Exception as e:\n",
        "        disp = ConfusionMatrixDisplay.from_predictions(\n",
        "        y_true, y_pred,\n",
        "        cmap = plt.cm.Blues,\n",
        "        xticks_rotation='vertical')\n",
        "\n",
        "  disp.ax_.set_title(config_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for config in configurations:\n",
        "  evaluate_model(config)"
      ],
      "metadata": {
        "id": "URb1XhrrZbrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edIfaY5Qzm6c"
      },
      "source": [
        "## Get all incorrect LLM responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-035VXHEzsoR"
      },
      "outputs": [],
      "source": [
        "def get_incorrect_answers(config):\n",
        "  output_dir = os.path.join(\"output\", config['name'].replace(' ', '_').lower())\n",
        "\n",
        "  # Get a boolean mask for every incorrect prediction\n",
        "  incorrect = np.array(config['y_pred']) != np.array(config['y_true'])\n",
        "\n",
        "  # Get the index of every incorrect prediction\n",
        "  index = np.array(list(range(test_data.num_rows)))[incorrect]\n",
        "\n",
        "  # Get every incorrect predicted label\n",
        "  incorrect_labels = np.array(config['y_pred'])[incorrect]\n",
        "\n",
        "  incorrect_answers = {\n",
        "      # Obtain title and content of article\n",
        "      \"Title\" : np.array([item['title'] for item in test_data])[incorrect],\n",
        "      \"Content\" : np.array([item['content'] for item in test_data])[incorrect],\n",
        "\n",
        "      # Get the class names for y_pred and y_true\n",
        "      \"Predicted Category\" : [CLASS_LABELS[id] for id in np.array(config['y_pred'])[incorrect]],\n",
        "      \"Actual Category\" : [CLASS_LABELS[id] for id in np.array([item['label'] for item in test_data])[incorrect]],\n",
        "\n",
        "      # Get LLM raw text output\n",
        "      \"LLM Output\" : np.array(config['responses'])[incorrect]\n",
        "  }\n",
        "\n",
        "  incorrect_answers = pd.DataFrame(incorrect_answers, index=index)\n",
        "\n",
        "  incorrect_answers.to_csv( os.path.join(output_dir, \"incorrect_answers.csv\"), escapechar='\\\\' )\n",
        "\n",
        "  return incorrect_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Uj7W6fSLE7Q"
      },
      "outputs": [],
      "source": [
        "for config in configurations:\n",
        "  get_incorrect_answers(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQSV83nSQCsg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}