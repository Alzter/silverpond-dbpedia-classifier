{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Company',\n",
       " 'EducationalInstitution',\n",
       " 'Artist',\n",
       " 'Athlete',\n",
       " 'OfficeHolder',\n",
       " 'MeanOfTransportation',\n",
       " 'Building',\n",
       " 'NaturalPlace',\n",
       " 'Village',\n",
       " 'Animal',\n",
       " 'Plant',\n",
       " 'Album',\n",
       " 'Film',\n",
       " 'WrittenWork']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"fancyzhx/dbpedia_14\")\n",
    "CLASS_LABELS = ds['train'].features['label'].names\n",
    "CLASS_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain first n samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_samples_per_class(dataset, n, shuffle = False):\n",
    "    \"\"\"\n",
    "        Given a test dataset, select n samples from each class\n",
    "        and return a smaller dataset containing all the samples.\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): The test dataset to sample.\n",
    "            n (int): How many samples from each class to extract.\n",
    "            shuffle (bool): Whether to sort the final result by class or randomly. NOTE: Dataset.shuffle() hangs indefinitely on Nix.\n",
    "        \n",
    "        Returns:\n",
    "            sample (Dataset): The sampled dataset.\n",
    "    \"\"\"\n",
    "    ds_sorted = dataset.sort('label')\n",
    "    _, class_indices = np.unique(ds_sorted['label'], return_index=True)\n",
    "\n",
    "    \n",
    "    class_indices = np.array([list(range(index, index + n)) for index in class_indices])\n",
    "    class_indices = class_indices.flatten()\n",
    "\n",
    "    if shuffle:\n",
    "        sample = dataset.shuffle().sort('label').select(class_indices) # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
    "    else:\n",
    "        sample = dataset.sort('label').select(class_indices)\n",
    "    \n",
    "    if shuffle: sample = sample.shuffle() # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = get_n_samples_per_class(ds['test'], 3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'title': 'TY KU',\n",
       " 'content': \" TY KU /taɪkuː/ is an American alcoholic beverage company that specializes in sake and other spirits. The privately-held company was founded in 2004 and is headquartered in New York City New York. While based in New York TY KU's beverages are made in Japan through a joint venture with two sake breweries. Since 2011 TY KU's growth has extended its products into all 50 states.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt to classify articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You are an expert in classifying articles into categories.\n",
    "Your task is to read an article, decide which category it belongs into, and then return the number of that category.\n",
    "There are 14 categories you may choose from, but you can only decide one category.\n",
    "\n",
    "CATEGORIES:\n",
    "1. Company\n",
    "2. Educational Institution\n",
    "3. Artist\n",
    "4. Athlete\n",
    "5. Office Holder\n",
    "6. Method Of Transportation\n",
    "7. Building\n",
    "8. Natural Place\n",
    "9. Village\n",
    "10. Animal\n",
    "11. Plant\n",
    "12. Album\n",
    "13. Film\n",
    "14. Written Work\n",
    "\n",
    "Read the following article and return only the number of its category. Do NOT return any text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_prompt(article):\n",
    "    \"\"\"\n",
    "        For a given article in the Dataset,\n",
    "        return a LLM prompt in chat template form\n",
    "        to get its category.\n",
    "\n",
    "        Args:\n",
    "            article (Dictionary): Any item in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            prompt (Dictionary): The prompt as a [Chat Template](https://huggingface.co/docs/transformers/main/en/chat_templating).\n",
    "    \"\"\"\n",
    "    return [\n",
    "      {\"role\": \"system\", \"content\": PROMPT},\n",
    "      {\"role\": \"user\", \"content\": article[\"content\"].strip()},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the LLM (C4AI Command R7B), you will need to accept a license agreement on Hugging Face.\n",
    "\n",
    "STEPS:\n",
    "1. Log into hugging face\n",
    "2. Accept the license agreement [here](https://huggingface.co/CohereForAI/c4ai-command-r7b-12-2024)\n",
    "3. Replace variable ``YOUR_HF_TOKEN`` with your Hugging Face token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67cc35540d6406281fe7fdda784f9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/8.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6bfaaf5f6946a895980df0105b15f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/12.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f7ab6c782242148270209f582fb28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/439 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c924bd16b99b4ebf8ac7f07fca2b8770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/634 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd3a670b5834bf0862decdc46bb90cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/21.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2db631bdb745e3bb088ddd832ff5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c154036ceaf44e8b0b677016c81fe6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af61e719c37b49d6adc845c750dde34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"CohereForAI/aya-expanse-8b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Format message with the c4ai-command-r7b-12-2024 chat template\n",
    "messages = get_classification_prompt(small_dataset[0])\n",
    "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=10,\n",
    "    do_sample=True,\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "gen_text = tokenizer.decode(gen_tokens[0], skip_special_tokens=True)\n",
    "print(gen_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
