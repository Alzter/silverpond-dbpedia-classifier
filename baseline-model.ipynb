{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKRSEolKGDiw"
      },
      "source": [
        "# Load DBPedia dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCnfFuWPWr9-"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"fancyzhx/dbpedia_14\")\n",
        "CLASS_LABELS = ds['train'].features['label'].names\n",
        "CLASS_LABELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY442nBwWr-A"
      },
      "source": [
        "# Obtain first n samples from each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dvYnTRrWr-C"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4j8rSsCWr-D"
      },
      "outputs": [],
      "source": [
        "def get_n_samples_per_class(dataset, n, shuffle = False):\n",
        "    \"\"\"\n",
        "        Given a test dataset, select n samples from each class\n",
        "        and return a smaller dataset containing all the samples.\n",
        "\n",
        "        Args:\n",
        "            dataset (Dataset): The test dataset to sample.\n",
        "            n (int): How many samples from each class to extract.\n",
        "            shuffle (bool): Whether to sort the final result by class or randomly. NOTE: Dataset.shuffle() hangs indefinitely on Nix.\n",
        "\n",
        "        Returns:\n",
        "            sample (Dataset): The sampled dataset.\n",
        "    \"\"\"\n",
        "    ds_sorted = dataset.sort('label')\n",
        "    _, class_indices = np.unique(ds_sorted['label'], return_index=True)\n",
        "\n",
        "\n",
        "    class_indices = np.array([list(range(index, index + n)) for index in class_indices])\n",
        "    class_indices = class_indices.flatten()\n",
        "\n",
        "    if shuffle:\n",
        "        sample = dataset.shuffle().sort('label').select(class_indices) # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
        "    else:\n",
        "        sample = dataset.sort('label').select(class_indices)\n",
        "\n",
        "    if shuffle: sample = sample.shuffle() # Dataset.shuffle() hangs indefinitely on Nix - No idea why.\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPbBqs74Wr-E"
      },
      "outputs": [],
      "source": [
        "small_dataset = get_n_samples_per_class(ds['test'], 3, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46yLfxYMWr-H"
      },
      "source": [
        "# Prompt to classify articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qQAMgasWr-H"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"\"\"You are an expert in classifying articles into categories.\n",
        "Your task is to read an article, decide which category it belongs into, and then return the number of that category.\n",
        "There are 14 categories you may choose from, but you can only decide one category.\n",
        "\n",
        "CATEGORIES:\n",
        "0. Company\n",
        "1. Educational Institution\n",
        "2. Artist\n",
        "3. Athlete\n",
        "4. Office Holder\n",
        "5. Method Of Transportation\n",
        "6. Building\n",
        "7. Natural Place\n",
        "8. Village\n",
        "9. Animal\n",
        "10. Plant\n",
        "11. Album\n",
        "12. Film\n",
        "13. Written Work\n",
        "\n",
        "Read the following article and return the most suitable category as a number (\"0\"), NOT as text (\"Company\").\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gq0uPzxWr-I"
      },
      "outputs": [],
      "source": [
        "def get_classification_prompt(article):\n",
        "    \"\"\"\n",
        "        For a given article in the Dataset,\n",
        "        return a LLM prompt in chat template form\n",
        "        to get its category.\n",
        "\n",
        "        Args:\n",
        "            article (Dictionary): Any item in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            prompt (Dictionary): The prompt as a [Chat Template](https://huggingface.co/docs/transformers/main/en/chat_templating).\n",
        "    \"\"\"\n",
        "    return [\n",
        "      {\"role\": \"system\", \"content\": PROMPT},\n",
        "      {\"role\": \"user\", \"content\": article[\"content\"].strip()},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coDi5e9WWr-K"
      },
      "source": [
        "# Load LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmWm8kV9Wr-K"
      },
      "source": [
        "To access the LLM (C4AI Command R7B), you will need to accept a license agreement on Hugging Face.\n",
        "\n",
        "STEPS:\n",
        "1. Log into hugging face\n",
        "2. Accept the license agreement [here](https://huggingface.co/CohereForAI/c4ai-command-r7b-12-2024)\n",
        "3. Replace variable ``YOUR_HF_TOKEN`` with your Hugging Face token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kihhy5KlWr-L"
      },
      "outputs": [],
      "source": [
        "HF_TOKEN = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCtNgkdbeVHT"
      },
      "outputs": [],
      "source": [
        "from accelerate.test_utils.testing import get_backend\n",
        "\n",
        "DEVICE, _, _ = get_backend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpf3SAVJWr-L"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"CohereForAI/c4ai-command-r7b-12-2024\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN, device_map=\"auto\")\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, token=HF_TOKEN, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W56z0RHRf3mL"
      },
      "outputs": [],
      "source": [
        "import transformers, torch\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    token=HF_TOKEN,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Un3PF5fr-1"
      },
      "source": [
        "# Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3Dt-uW3dmLj"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_category_label(article):\n",
        "  \"\"\"\n",
        "  For a given article in the DBPedia dataset, predict its category label.\n",
        "\n",
        "  Args:\n",
        "    article (str): Article contents as raw text.\n",
        "\n",
        "  Returns:\n",
        "    label (int): The category of the article.\n",
        "  \"\"\"\n",
        "  input = get_classification_prompt(article)\n",
        "\n",
        "  chat_history = pipeline(\n",
        "      input,\n",
        "      do_sample=True,\n",
        "      #top_k=10,\n",
        "      #num_return_sequences=1,\n",
        "      eos_token_id=tokenizer.eos_token_id,\n",
        "      max_new_tokens=10,\n",
        "      temperature=0.001\n",
        "      #continue_final_message=continue_final_message\n",
        "  )\n",
        "\n",
        "  response = chat_history[0][\"generated_text\"][-1]['content']\n",
        "\n",
        "  response_number=re.findall(r\"\\d+\",response)\n",
        "  if response_number is not None:\n",
        "    response_number = int(response_number[0])\n",
        "    return response_number\n",
        "  else:\n",
        "    raise Exception(f\"No number found in LLM response: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xhhly4zjscN"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def predict_classes(dataset):\n",
        "  \"\"\"\n",
        "    For a given RFPedia dataset, use the contents of each article to predict its label.\n",
        "\n",
        "    Args:\n",
        "      dataset (Dataset): The dataset to sample.\n",
        "\n",
        "    Returns:\n",
        "      results (tuple<list, list>): Two lists: ``y_pred`` (predicted labels) and ``y_true`` (actual labels).\n",
        "  \"\"\"\n",
        "  y_pred = []\n",
        "  y = []\n",
        "\n",
        "  for item in tqdm(dataset):\n",
        "    y_pred.append( get_category_label(item) )\n",
        "    y.append( item['label' ])\n",
        "\n",
        "  return y_pred, y_true"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict all article categories in the dataset\n",
        "\n",
        "y_pred, y_true = predict_classes(small_dataset['test'])"
      ],
      "metadata": {
        "id": "0gx668V-G5ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model"
      ],
      "metadata": {
        "id": "o4Ib_XV9GKIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get precision, recall, and F1 score for all classes"
      ],
      "metadata": {
        "id": "ajAnOGoqIamW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "classif_report = classification_report(y_true, y_pred)"
      ],
      "metadata": {
        "id": "hmkxjb4_GLBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get confusion matrix"
      ],
      "metadata": {
        "id": "hy8DJbTQIbbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=CLASS_LABELS)\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "    display_labels = CLASS_LABELS,\n",
        "    cmap = plt.cm.Blues,\n",
        "    normalize=True)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W30Tjn9uHhnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}